In December 2019, Pete Warden and Daniel Situnayake of Google's AI research group published a book titled \textit{"TinyML: Machine Learning with TensorFlow Lite on Arduino and Ultra-Low-Power Microcontrollers"}. In this work, they take on the challenge of reducing the complexity and, very importantly, size, of TensorFlow Lite model architectures (originally designed for use on smartphones) to such an extent that they are realistically deployable to more constrained embedded devices and systems. The book defines the main working principles of running machine learning on embedded devices. \cite{tinyml_book} The term \textit{TinyFace}, which was coined for the title of this thesis and, more broadly for the research project this thesis is a part of, is, therefore, a word-play on the title of the \textit{TinyML} book, which was instrumental in the development of this thesis, and we want to acknowledge this from the very start. \par
Machine Learning (ML), a subclass of Artificial Intelligence (AI), is simply an \textit{umbrella term} for many different systematized techniques one uses to teach a computer or make it learn by itself how to perform traditionally \textit{human-only} activities. These could be tasks such as making \textit{predictions} or \textit{classifications} and, more generally, understanding a larger context, with the intent of earning insight and creating something new from a given input. In fewer words, Machine Learning means a computer trains itself to draw conclusions from existing data, and generate new data. That is to be done \textit{without} deterministic algorithms, in the traditional computer programming sense - by this, we mean that \textit{we do not program the AI ourselves, but that it trains itself} and that the results will vary, within a certain margin, for different runs, even with the same input. \cite{Goodfellow-et-al-2016} But let us not understand from this that there won't be any algorithms at all; just the opposite. As a matter of fact, there will be, almost without exception, numerical programming, just not necessarily that much logical code (expressions, conditionals, loops, and such). As practical examples, let us take smartphone fingerprint sensors, or face detection sensor-arrays, which will often leverage ML pattern recognition to detect whether it truly is the actual owner of the phone who is trying to gain access, and decide whether to let him or her in. Or social media apps, which use AI detectors, for adding face filters to selfies, E-mail providers who use AI classifiers as spam filters, banks which often have regression-based AI protection against credit card fraud, or high-frequency trading firms, which often also rely on ML technology, such as random forests, for split-second decision making when buying, and selling, securities, or generative adversarial networks, which can generate new data, which, at least superficially, appears realistic. \cite{gans_goodfellow} A more detailed overview will be offered in Chapter 2. \par
The more specific sub-category of machine learning methods this thesis focuses on is deep, convolutional neural networks. These are incredibly complex systems processing vast mathematical structures, which traditionally require such high computing power to be useful for anything, that they could only really be deployed outside of scientific applications and laboratories, and into the real, consumer-world products in just the past two decades. With increasing hardware per-watt performance and dramatic price drops in manufacturing costs, machine learning has started moving \textit{down from the cloud} and into end-user devices. First, that meant having ML on smaller servers in a back room, then on desk computers and laptops, and, in more recent years, on smartphones. The next step is bringing these techniques to ever smaller, embedded devices, such as micro-controller boards, which are the next great frontier in this field. \par
The motivation for bringing ML technology to tiny computers can be quickly formulated as feeding the ever-increasing need of the world for small, connected, electronic devices, to be deployed everywhere and be available around-the-clock, while taking on more and more tasks, fulfilling them reliably, accurately and repeatedly, and, on top of that, is also being expected to drop in price and grow in performance and speed. TinyFace, therefore, attempts to offer a contribution in the new field of small-scale face detection, namely detecting, with a camera, if a human being presented herself in front of the device. This could, for instance, be useful in a security application, where a smaller, embedded, camera device would detect whether a person has appeared before it, than wake up a larger computer to perform full facial recognition, in a similar fashion to how wake words work for digital assistants. \par
A typical machine learning development flow consists, most of the time, of compiling adequate datasets in terms of representation, size, and quality, building model architectures for the used convolutional neural networks and specifically defining their layer architecture in terms of size, type, and number of layers, then leveraging the dataset for training the neural network model. \textit{Training} is the process of feeding data in a controlled and feedback-bound manner into a mathematical model with the scope of \textit{teaching} it to perform a task that would require human intuition. After having trained a model to an acceptable level of performance, we can move on to using it in real-world applications. This step is called \textit{inference}. ML on embedded systems is expected to only do inference on the MCU, with neural-network training and optimization being done off-device. Machine learning on embedded devices and specifically face-detection will be addressed in Chapters 3 and 4, respectively. \par
The technologies used for TinyFace are frameworks such as TensorFlow (Lite), which offer us the necessary tools to construct and train neural networks, as well as processes to make them fit on our embedded hardware, such as bit-level quantization, model compression and weight-pruning techniques. Furthermore, a data-collection and dataset-compilation workflow, training and evaluation routine, as well as a practical application, are presented. This will be the subject of Chapters 5 and 6. \par
Without any further ado, let us proceed to the next chapter, where several Machine Learning techniques, as well as some field-specific terminology, will be discussed, and where we will present a theoretical background for the subsequent chapters.