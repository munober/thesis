In the past chapters, we have walked through the steps of developing a workflow for building face detection systems for MCU hardware. \par

This thesis started out with a formulation of the problem of running machine learning-class applications on very constrained edge-devices, specifically neural network type applications for face detection. The second chapter offered a quick introduction into machine learning, whereas the third chapter went into depth about the memory limitations of embedded devices. Chapter 4 helped the reader understand which steps could be undertaken to overcome the limitations of edge devices, as well as how the author decided which model architectures and training data to use for the presented practical project. The fifth and sixth chapters went into specific details about the practical project and presented a discussion of the achieved results and their implications. \par
This last chapter will be the place where we present possible future research directions for TinyFace, and draw some conclusions. \par
\section{Deployment to Embedded Hardware}
It is the final goal of the author to have his trained model run on embedded hardware eventually. This will be the goal of future research. So far, we have identified 2 ways to accomplish this. Firstly, we can run an \textit{offline interpreter}, on-device, having the model saved as a flat buffer, instead of a graph, in memory. This is quite versatile and can run most models flawlessly, however, it comes with relatively large memory and performance overheads. As such, it is often too much for STM32 boards to handle. The second option is to use a direct model compiler, which can translate \textit{.tflite} files into \textit{C++} programs, that can compile directly. This option requires even less overhead, since we have no need to load the TensorFlow operations separately into memory. With both options, we estimate that we would use up a maximum of 900 KB of memory in total, with our own model, on top of the usual MCU code. \par
In addition to running the above-named task, we need some firmware on-device, to handle the hardware inputs (camera capture) and outputs (display and LED handling). To this end, we are planning to use STM's stock firmware, which includes a bare-bones real-time operating system, that still offers scheduling and synchronization mechanisms.
\section{Automating Model Optimization and Training}
There is, in essence, one topic that we think should be addressed here. That is the problem of automatic hyper-parameter optimization. \textit{Grid Search} promises a solution to this issue. \par
As mentioned in the previous chapters, the choice of hyper-parameters is often approached as a trial-and-error process, where the programmer experiments with different values, incrementally increasing performance until a satisfactory level is achieved. However, given the large impact hyper-parameter choice can have on the final accuracy of inference and how long it can take to find the right combination of training parameters manually, it might actually be smarter to automate this task. \par
\textit{Grid search} offers a solution to this problem. \cite{scikit_grid_search} As implemented in the \textit{SciKit} library, grid search enables us to try out different hyperparameters with our model during training. We can provide the script with either a list of values we would want it to try out autonomously, or we can, more broadly, define a plane of values (combined set of ranges), where the system will look for optimal values. We also have to provide a performance metric to evaluate the performance and help determine the optimal combinations. We can even train more models in parallel to speed up the process. As such, this has the potential to completely change how we will be doing model training for TinyFace.
\section{Final Remarks}
This work has presented a possible pathway for developing a face detector, with one's own gathered data and any ML model one desires. The contribution to the field of \textit{tiny} Machine Learning is the fact that convolutional neural networks have been added into the model architecture. Tiny Machine Learning is itself a very new field, and the literature on the topic is still being written. The tools themselves are being actively developed and substantial changes are made at leasy once every month to the open-source code and API's that had been used to develop this project. This goes on to show just how much we can add to this field. \par
This being said, the author hopes this work has at least provided a useful insight into what is possible on such tiny hardware, and what embedded machine learning has to offer.